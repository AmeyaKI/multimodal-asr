{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbx+tEWwFO4M9mRFRiYI2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeyaKI/multimodal-asr/blob/main/ml/b_asr/asr_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrJA9-uuas1f",
        "outputId": "7307e723-25ae-4441-bcf5-0d5d485cfeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install jiwer\n",
        "from jiwer import wer, cer\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoProcessor, AutoModelForCTC\n",
        "import librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tRAg9c-avpx",
        "outputId": "fe274812-e980-41c3-bd37-8003539569d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CLASS AND FUNCTION _IFY LATER\n",
        "# add error checking statements\n",
        "\n",
        "\n",
        "file_name = 'file00000' + '.wav' # file_name from mic_vad.py\n",
        "recordings_path = Path(f'{Path.cwd()}/drive/MyDrive/Colab Notebooks/assistant/vad_recordings') # Path.is_dir() and Path.exists()\n",
        "file_path = recordings_path / file_name\n",
        "file_path"
      ],
      "metadata": {
        "id": "QAZpUqDxblIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f2b7b1-425c-455a-f05d-916150055eb9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/Colab Notebooks/assistant/vad_recordings/file00000.wav')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDt36P5f1E4v",
        "outputId": "0970edd3-38b3-4a81-ac3c-0e507fffecd7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ASR():\n",
        "  DEFAULT_MODEL = 'nvidia/parakeet-ctc-1.1b' # train custom model\n",
        "  DEFAULT_DEVICE = 'cuda'\n",
        "  TARGET_SAMPLE_RATE = 16000 # resample to 16,000 hz\n",
        "\n",
        "\n",
        "  def __init__(self, custom_model=None, device=None):\n",
        "    self.model_name = custom_model or self.DEFAULT_MODEL\n",
        "    self.device = device or self.DEFAULT_DEVICE\n",
        "\n",
        "    self.processor = AutoProcessor.from_pretrained(self.model_name)\n",
        "    self.model = AutoModelForCTC.from_pretrained(self.model_name, dtype='auto').to(self.device)\n",
        "    self.model.eval()\n",
        "\n",
        "  def process_audio(self, audio_path):\n",
        "    if audio_path is None:\n",
        "      raise ValueError\n",
        "\n",
        "    # load audio\n",
        "    waveform, sample_rate = librosa.load(\n",
        "        audio_path,\n",
        "        sr=None,\n",
        "        mono=True)\n",
        "\n",
        "    # resample if sample_rate is incorrect\n",
        "    if sample_rate != self.TARGET_SAMPLE_RATE:\n",
        "        waveform = librosa.resample(\n",
        "            waveform,\n",
        "            orig_sr = sample_rate,\n",
        "            target_sr = self.TARGET_SAMPLE_RATE)\n",
        "\n",
        "    # normalizing audio amp\n",
        "    max_val = np.max(np.abs(waveform))\n",
        "    if max_val > 0:\n",
        "        waveform /= max_val\n",
        "    return waveform\n",
        "\n",
        "\n",
        "  def transcribe(self, audio_path):\n",
        "    waveform = self.process_audio(audio_path)\n",
        "\n",
        "    # calc model inputs\n",
        "    model_inputs = self.processor(\n",
        "        waveform,\n",
        "        sampling_rate = self.TARGET_SAMPLE_RATE,\n",
        "        return_tensors = 'pt'\n",
        "        )\n",
        "\n",
        "    model_inputs = model_inputs.to(\n",
        "        device = self.model.device,\n",
        "        dtype = self.model.dtype\n",
        "        )\n",
        "\n",
        "    with torch.no_grad(): # obtain logits\n",
        "        # Ensure input_features are in bfloat16 to match model's dtype\n",
        "        model_inputs.input_features = model_inputs.input_features.to(torch.bfloat16)\n",
        "        logits = self.model(**model_inputs).logits\n",
        "\n",
        "    # decode and translate logits to predicted text\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = self.processor.batch_decode(predicted_ids)\n",
        "    predicted_text = transcription[0]\n",
        "\n",
        "    return predicted_text"
      ],
      "metadata": {
        "id": "3cNEqRJs1zcx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr_model = ASR()"
      ],
      "metadata": {
        "id": "ySm0Tq149Xdb"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr_model.transcribe(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3xr1UaGq9fxB",
        "outputId": "8c9e43b6-c972-4874-d5c2-8de3506ba568"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one two three one two three'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}